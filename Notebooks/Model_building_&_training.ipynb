{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3991944f",
   "metadata": {},
   "source": [
    "### <div align=\"center\">***MODEL BUILDING AND TRAINING***</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82302733",
   "metadata": {},
   "source": [
    "### ***Import libraries and modules***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5a92f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "import mlflow\n",
    "import dagshub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"_distutils_hack\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"mlflow.data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4939197a",
   "metadata": {},
   "source": [
    "### ***Preprocessing dataset for Modeling***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcc1c446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Clean Dataset\n",
    "fe_dataset = pd.read_csv(r'C:\\Users\\spand\\Projects\\LABMENTIX_PROJECTS\\Amazon_DeliveryTime_Prediction\\Data\\Processed\\EDA_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16ff8ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 43648 entries, 0 to 43647\n",
      "Data columns (total 15 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Agent_Age      43648 non-null  int64  \n",
      " 1   Agent_Rating   43648 non-null  float64\n",
      " 2   Weather        43648 non-null  object \n",
      " 3   Traffic        43648 non-null  object \n",
      " 4   Vehicle        43648 non-null  object \n",
      " 5   Area           43648 non-null  object \n",
      " 6   Delivery_Time  43648 non-null  int64  \n",
      " 7   Category       43648 non-null  object \n",
      " 8   Distance_km    43648 non-null  float64\n",
      " 9   Order_Hour     43648 non-null  int64  \n",
      " 10  Traffic_Area   43648 non-null  object \n",
      " 11  Area_Vehicle   43648 non-null  object \n",
      " 12  Weather_Area   43648 non-null  object \n",
      " 13  Is_Peak_Hours  43648 non-null  int64  \n",
      " 14  Is_Urban       43648 non-null  int64  \n",
      "dtypes: float64(2), int64(5), object(8)\n",
      "memory usage: 5.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df = fe_dataset.copy()\n",
    "\n",
    "# Interactive features\n",
    "df['Traffic_Area'] = df['Traffic'].astype(str) + \"_\" + df['Area'].astype(str)\n",
    "df['Area_Vehicle'] = df['Area'].astype(str) + \"_\" + df['Vehicle'].astype(str)\n",
    "df['Weather_Area'] = df['Weather'].astype(str) + \"_\" + df['Area'].astype(str)\n",
    "\n",
    "df['Is_Peak_Hours'] = df['Order_Hour'].apply(lambda x: 1 if (17 <= x <= 23) else 0) # Create peak hours from order hours\n",
    "df['Is_Urban'] = df['Area'].apply(lambda x: 1 if x in ['Urban', 'Metropolitan'] else 0) # Collapse to Binary (Urban vs Non-Urban)\n",
    "\n",
    "df = df.drop([\"Delay_Time_M\", \"Order_Month\", \"Order_DayOfWeek\", \"Order_Day\", \"Is_Weekend\"], axis=1) # Drop features with no predictive power\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f79484d",
   "metadata": {},
   "source": [
    "#### ***Train-Val-Test split*** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4786501f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (30553, 14), Val: (6547, 14), Test: (6548, 14)\n"
     ]
    }
   ],
   "source": [
    "# Define target\n",
    "TARGET = \"Delivery_Time\"\n",
    "train_df, val_test_df = train_test_split(df, test_size=0.3, random_state=42) # First split Train (70%) & Val+Test (30%)\n",
    "val_df, test_df = train_test_split(val_test_df, test_size=0.5, random_state=42) # Second split Validation (15%) & Test (15%)\n",
    "\n",
    "X_train, y_train = train_df.drop(columns=TARGET), train_df[TARGET]\n",
    "X_val, y_val = val_df.drop(columns=TARGET), val_df[TARGET]\n",
    "X_test, y_test = test_df.drop(columns=TARGET), test_df[TARGET]\n",
    "\n",
    "print(f\"Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77f9343",
   "metadata": {},
   "source": [
    "### ***Prepocessing Pipeline***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4683d8",
   "metadata": {},
   "source": [
    "#### ***Outlier Handling & Skewness Correction***\n",
    "\n",
    "***As observed from univariate analysis, Delivery_Time, Distance_km and Order_Hour are skewed with outliers.***\n",
    "- ***Delivery_Time (target):*** left untouched \n",
    "- ***Order_Hour:*** bimodal, temporal pattern â†’ keep raw\n",
    "- ***Agent_Rating:*** bounded [1â€“5], skew due to natural bias â†’ keep raw \n",
    "- ***Distance_km:*** extreme skew & heavy-tailed â†’ cap + log transform (if needed) âœ…\n",
    "\n",
    "#### ***Encode categorical features***\n",
    "- ***Define low & high cardinality feature groups***\n",
    "- Apply One-hot Encoding for low cardinality features\n",
    "- Apply Target Encoding for high cardinality features (Interactive features)\n",
    "\n",
    "#### ***Scaling numerical features + target-encoded features***\n",
    "- Apply ***StandardScalar()*** on numerical + target-encoded features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f94c8363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier & Skew transformer\n",
    "class OutlierSkewHandler(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features, skew_threshold=1.0, quantile=0.99):\n",
    "        self.features = features\n",
    "        self.skew_threshold = skew_threshold\n",
    "        self.quantile = quantile\n",
    "        self.upper_limits_ = {}\n",
    "        self.log_features_ = []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        for col in self.features:\n",
    "            self.upper_limits_[col] = X[col].quantile(self.quantile)\n",
    "            capped = np.where(X[col] > self.upper_limits_[col], self.upper_limits_[col], X[col])\n",
    "            if pd.Series(capped).skew() > self.skew_threshold:\n",
    "                self.log_features_.append(col)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for col in self.features:\n",
    "            X[col] = np.where(X[col] > self.upper_limits_[col], self.upper_limits_[col], X[col])\n",
    "            if col in self.log_features_:\n",
    "                X[col] = np.log1p(X[col])\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "294ab723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Preprocessing pipeline\n",
    "\n",
    "# Feature groups\n",
    "low_card_feats  = [\"Weather\", \"Traffic\", \"Vehicle\", \"Area\"]\n",
    "high_card_feats = [\"Category\", \"Traffic_Area\", \"Area_Vehicle\", \"Weather_Area\"]\n",
    "num_feats = [\"Agent_Age\", \"Agent_Rating\", \"Distance_km\", \"Order_Hour\"]\n",
    "\n",
    "# Custom transformers\n",
    "outlier_skew = OutlierSkewHandler(features=[\"Distance_km\"], skew_threshold=1.0)\n",
    "ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "target_enc = TargetEncoder(cols=high_card_feats)\n",
    "\n",
    "# Column transformer (numerics + OHE)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), num_feats + high_card_feats),\n",
    "        (\"ohe\", ohe, low_card_feats)\n",
    "    ],\n",
    "    remainder=\"drop\"  # ðŸš¨ prevent leakage\n",
    ")\n",
    "\n",
    "# Full preprocessing pipeline\n",
    "full_preprocessing_pipeline = Pipeline(steps=[\n",
    "    (\"outlier_skew\", outlier_skew),\n",
    "    (\"encode_target\", target_enc),\n",
    "    (\"preproc\", preprocessor)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb7332ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper: preprocessing + model\n",
    "def make_pipeline(model):\n",
    "    return Pipeline(steps=[\n",
    "        (\"preprocessing\", full_preprocessing_pipeline),\n",
    "        (\"model\", model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292254bb",
   "metadata": {},
   "source": [
    "### ***Setup DagsHub MLflow***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac147e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Set MLflow tracking to your project root \"mlruns\" folder\n",
    "mlflow.set_tracking_uri(\"file:///C:/Users/spand/Projects/LABMENTIX_PROJECTS/Amazon_DeliveryTime_Prediction/mlruns\")\n",
    "mlflow.set_experiment(\"Amazon_delivery_time_prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949775c1",
   "metadata": {},
   "source": [
    "### ***Model Building, Training & Evaluation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "84193d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics helper functions\n",
    "def metrics_report(y_true, y_pred):\n",
    "    return {\n",
    "        \"rmse\": np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        \"mae\": mean_absolute_error(y_true, y_pred),\n",
    "        \"r2\": r2_score(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "def print_eval(name, y_true, y_pred):\n",
    "    m = metrics_report(y_true, y_pred)\n",
    "    print(f\"{name} -> RMSE: {m['rmse']:.4f} | MAE: {m['mae']:.4f} | R2: {m['r2']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f101a8",
   "metadata": {},
   "source": [
    "#### ***Baseline Models***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e1e82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/02 00:16:31 INFO mlflow.tracking.fluent: Experiment with name 'Amazon_delivery_time_prediction' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "# Define baseline models\n",
    "models = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"Ridge\": Ridge(random_state=42),\n",
    "    \"RandomForest\": RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1),\n",
    "    \"GradientBoosting\": GradientBoostingRegressor(n_estimators=200, random_state=42),\n",
    "    \"XGBoost\": xgb.XGBRegressor(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dede68",
   "metadata": {},
   "source": [
    "***Validation Performance (Main Criteria)***\n",
    "- The goal is to minimize Val RMSE (lower is better).\n",
    "- RandomForest (23.23) and XGBoost (23.23) are nearly identical, both much better than GradientBoosting (24.29) and far better than Ridge/Linear (32+).\n",
    "- So RandomForest & XGBoost are the top contenders.\n",
    "\n",
    "***Overfitting Check***\n",
    "- RandomForest: Train RMSE = 8.42 vs Val RMSE = 23.23 â†’ Big gap â†’ model fits training data extremely well but generalizes less strongly.\n",
    "- XGBoost: Train RMSE = 17.24 vs Val RMSE = 23.23 â†’ Smaller gap â†’ slightly better generalization than RandomForest.\n",
    "- Both still generalize well, but RandomForest shows stronger overfitting.\n",
    "\n",
    "***RÂ² Scores (Explained Variance)***\n",
    "- RandomForest: 0.97 (train) â†’ ~ 0.80 (val)\n",
    "- XGBoost: 0.88 (train) â†’ ~ 0.80 (val)\n",
    "- Both capture ~80% of variance on validation set.\n",
    "\n",
    "***Even though XGBoost is very close, RandomForest edges out slightly on validation RMSE (23.2360 vs 23.2388) thought it shows more overfitting (big train-val gap). So let's:***\n",
    "- Get feature importances for both RandomForest and XGBoost.\n",
    "- Drop weak features (low contribution).\n",
    "- Hyperparameter tune both models with CV.\n",
    "- Track everything in MLflow (params, metrics, datasets, models)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1baa21",
   "metadata": {},
   "source": [
    "#### ***Extract Feature Importances***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de1d2f4",
   "metadata": {},
   "source": [
    "#### ***Hyperparameter Tune RF & XGB on reduced Feature set***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bc43e2",
   "metadata": {},
   "source": [
    "***Validation Performance (what really matters):***\n",
    "- RF has slightly lower RMSE/MAE â†’ better generalization.\n",
    "- RF Val_RMSE = 22.15 vs XGB = 22.41 (small edge to RF).\n",
    "- RF Val_MAE = 17.14 vs XGB = 17.43.\n",
    "- Val_RÂ² is basically the same (~0.818 vs 0.814).\n",
    "\n",
    "***Training Performance:***\n",
    "- XGB fits training data better (lower Train_RMSE/MAE, higher Train_RÂ²).\n",
    "- But thatâ€™s not necessarily good â†’ it might be slightly overfitting compared to RF.\n",
    "\n",
    "***âœ… Best Choice -> RandomForest***\n",
    "- Lower validation RMSE/MAE (your main metrics).\n",
    "- Slightly more balanced (less risk of overfitting)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57163885",
   "metadata": {},
   "source": [
    "#### ***Retrain on Train + Val with best model parameters***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2717ae",
   "metadata": {},
   "source": [
    "#### ***Interpretation***\n",
    "\n",
    "***Consistency (Good Generalization)***\n",
    "- Train+Val RMSE = 20.9 vs Test RMSE = 22.0 â†’ only a small gap.\n",
    "- Train+Val RÂ² = 0.838 vs Test RÂ² = 0.823 â†’ very close.\n",
    "- âœ… Model is not overfitting; generalizes well to unseen data.\n",
    "\n",
    "***Error Magnitude***\n",
    "- RMSE ~22 hours â†’ predictions deviate by ~22 hours on average.\n",
    "- MAE ~17 hours â†’ median absolute error is lower (robust to outliers).\n",
    "- Considering delivery times may range widely (short vs long trips), this error seems reasonable â€” since long-distance orders exist.\n",
    "\n",
    "***Residual Plot***\n",
    "- Residuals are mostly centered around 0 (good).\n",
    "- Spread increases with higher predicted values (heteroscedasticity).\n",
    "- Suggests model handles short/medium deliveries better, but variance grows for long delivery times (common in real logistics data).\n",
    "\n",
    "***Conclusion***\n",
    "- Hyperparameter tuned RandomForest model is performing very well\n",
    "- Balanced fit (Train â‰ˆ Test metrics).\n",
    "- Captures ~82% of variance in delivery times.\n",
    "- Errors are relatively stable across test set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
